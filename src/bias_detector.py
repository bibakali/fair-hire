"""
bias_detector.py
DÃ©tection de biais dans les offres d'emploi
"""

import re
from dataclasses import dataclass, field


# ---------------------------------------------------------------
# Dictionnaires de biais â€” enrichissables facilement
# ---------------------------------------------------------------

GENDERED_WORDS = {
    "masculins": [
        "ninja", "rockstar", "guru", "wizard", "hacker",
        "ambitieux", "combatif", "dominant", "compÃ©titif",
        "indÃ©pendant", "confiant", "assertif", "agressif"
    ],
    "feminins": [
        "collaboratif", "empathique", "doux", "attentionnÃ©",
        "discret", "patient", "bienveillant"
    ]
}

DISCRIMINATORY_PATTERNS = [
    r"\d{2}\s*[-â€“\s*et\s*]\d{2}\s*ans",  # 25-35 ans ou 25 et 35 ans
    r"\d{2}\s*ans",                        # "25 ans" seul
    r"jeune",
    r"apparence",
    r"prÃ©sentable",
    r"photos?",
    r"disponible\s*immÃ©diatement",
]

INCLUSIVE_ALTERNATIVES = {
    "ninja": "expert",
    "rockstar": "dÃ©veloppeur talentueux",
    "guru": "spÃ©cialiste",
    "wizard": "expert",
    "hacker": "dÃ©veloppeur crÃ©atif",
    "ambitieux": "motivÃ©",
    "combatif": "dÃ©terminÃ©",
    "dominant": "leadership",
    "jeune": "junior",
}


# ---------------------------------------------------------------
# Dataclass pour structurer les rÃ©sultats
# ---------------------------------------------------------------

@dataclass
class BiasReport:
    gendered_words_found: list[str] = field(default_factory=list)
    discriminatory_patterns_found: list[str] = field(default_factory=list)
    bias_score: float = 0.0          # 0 = neutre, 1 = trÃ¨s biaisÃ©
    suggestions: dict = field(default_factory=dict)
    rewritten_excerpt: str = ""
    summary: str = ""


# ---------------------------------------------------------------
# Fonctions principales
# ---------------------------------------------------------------

def detect_gendered_words(text: str) -> list[str]:
    """DÃ©tecte les mots genrÃ©s dans le texte."""
    text_lower = text.lower()
    found = []
    for genre, words in GENDERED_WORDS.items():
        for word in words:
            if word in text_lower:
                found.append(f"{word} ({genre})")
    return found


def detect_discriminatory_patterns(text: str) -> list[str]:
    """DÃ©tecte les patterns discriminatoires via regex."""
    text_lower = text.lower()
    found = []
    for pattern in DISCRIMINATORY_PATTERNS:
        matches = re.findall(pattern, text_lower)
        if matches:
            found.append(pattern)
    return found


def compute_bias_score(
    gendered: list[str],
    discriminatory: list[str],
    total_words: int
) -> float:
    """
    Calcule un score de biais entre 0 et 1.
    Plus le score est Ã©levÃ©, plus l'offre est biaisÃ©e.
    """
    if total_words == 0:
        return 0.0

    raw_score = (len(gendered) * 2 + len(discriminatory) * 3) / total_words * 100
    return round(min(raw_score, 1.0), 4)


def generate_suggestions(gendered_words: list[str]) -> dict:
    """GÃ©nÃ¨re des suggestions de remplacement pour les mots biaisÃ©s."""
    suggestions = {}
    for entry in gendered_words:
        word = entry.split(" (")[0]  # retire "(masculins)" ou "(feminins)"
        if word in INCLUSIVE_ALTERNATIVES:
            suggestions[word] = INCLUSIVE_ALTERNATIVES[word]
        else:
            suggestions[word] = "âš ï¸ Ã€ reformuler (pas d'alternative automatique)"
    return suggestions


def analyze(text: str) -> BiasReport:
    """
    Analyse complÃ¨te d'un texte pour dÃ©tecter les biais.

    Args:
        text: Texte de l'offre d'emploi

    Returns:
        BiasReport avec tous les rÃ©sultats
    """
    report = BiasReport()

    # DÃ©tections
    report.gendered_words_found = detect_gendered_words(text)
    report.discriminatory_patterns_found = detect_discriminatory_patterns(text)

    # Score
    total_words = len(text.split())
    report.bias_score = compute_bias_score(
        report.gendered_words_found,
        report.discriminatory_patterns_found,
        total_words
    )

    # Suggestions
    report.suggestions = generate_suggestions(report.gendered_words_found)

    # RÃ©sumÃ© lisible
    if report.bias_score == 0:
        report.summary = "âœ… Aucun biais dÃ©tectÃ©. L'offre semble inclusive."
    elif report.bias_score < 0.05:
        report.summary = f"âš ï¸ Biais faibles dÃ©tectÃ©s ({len(report.gendered_words_found)} mots genrÃ©s)."
    else:
        report.summary = f"ğŸš¨ Biais significatifs dÃ©tectÃ©s â€” reformulation recommandÃ©e."

    return report


def format_report(report: BiasReport) -> str:
    """Formate le rapport pour affichage."""
    lines = [
        "=" * 50,
        "RAPPORT D'ANALYSE DES BIAIS",
        "=" * 50,
        f"\nğŸ“Š Score de biais : {report.bias_score}",
        f"ğŸ“ RÃ©sumÃ© : {report.summary}",
    ]

    if report.gendered_words_found:
        lines.append(f"\nğŸ” Mots genrÃ©s dÃ©tectÃ©s :")
        for w in report.gendered_words_found:
            lines.append(f"  - {w}")

    if report.discriminatory_patterns_found:
        lines.append(f"\nğŸš« Patterns discriminatoires :")
        for p in report.discriminatory_patterns_found:
            lines.append(f"  - {p}")

    if report.suggestions:
        lines.append(f"\nğŸ’¡ Suggestions de remplacement :")
        for original, alternative in report.suggestions.items():
            lines.append(f"  - '{original}' â†’ '{alternative}'")

    lines.append("=" * 50)
    return "\n".join(lines)


# Test rapide si on lance ce fichier directement
if __name__ == "__main__":
    offre = """
    Nous recherchons un ninja du code, rockstar et ambitieux,
    entre 25 et 35 ans, prÃ©sentable et disponible immÃ©diatement.
    Vous Ãªtes indÃ©pendant, combatif et aimez les dÃ©fis techniques.
    """

    report = analyze(offre)
    print(format_report(report))