"""
embeddings.py
Transformation du texte en vecteurs numÃ©riques et stockage dans ChromaDB
"""

import os
from pathlib import Path
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings

load_dotenv()

# ModÃ¨le d'embedding lÃ©ger et efficace
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
CHROMA_PATH = os.getenv("CHROMA_PATH", "./chroma_db")


def get_embedding_model() -> SentenceTransformer:
    """
    Charge le modÃ¨le d'embedding.
    TÃ©lÃ©chargÃ© automatiquement au premier appel (~90Mo).
    """
    print(f"ðŸ“¦ Chargement du modÃ¨le d'embedding : {EMBEDDING_MODEL}")
    model = SentenceTransformer(EMBEDDING_MODEL)
    return model


def get_chroma_client() -> chromadb.Client:
    """
    Initialise le client ChromaDB en mode persistant.
    Les vecteurs sont sauvegardÃ©s sur disque dans CHROMA_PATH.
    """
    Path(CHROMA_PATH).mkdir(parents=True, exist_ok=True)
    client = chromadb.PersistentClient(path=CHROMA_PATH)
    return client


def embed_and_store(
    chunks: list[str],
    collection_name: str,
    metadata: dict = None
) -> chromadb.Collection:
    """
    Vectorise les morceaux de texte et les stocke dans ChromaDB.

    Args:
        chunks: Liste de morceaux de texte (depuis ingestion.py)
        collection_name: Nom de la collection ChromaDB (ex: "cv_john", "offre_dev")
        metadata: Infos supplÃ©mentaires sur le document (ex: type, nom fichier)

    Returns:
        La collection ChromaDB crÃ©Ã©e
    """
    model = get_embedding_model()
    client = get_chroma_client()

    # Supprime la collection si elle existe dÃ©jÃ  (rechargement propre)
    try:
        client.delete_collection(name=collection_name)
        print(f"ðŸ—‘ï¸  Collection existante supprimÃ©e : {collection_name}")
    except Exception:
        pass

    collection = client.create_collection(name=collection_name)

    # GÃ©nÃ©ration des embeddings
    print(f"âš™ï¸  Vectorisation de {len(chunks)} morceaux...")
    embeddings = model.encode(chunks, show_progress_bar=True).tolist()

    # PrÃ©paration des mÃ©tadonnÃ©es
    meta = metadata or {}
    metadatas = [{**meta, "chunk_index": i} for i in range(len(chunks))]
    ids = [f"{collection_name}_chunk_{i}" for i in range(len(chunks))]

    # Stockage dans ChromaDB
    collection.add(
        documents=chunks,
        embeddings=embeddings,
        metadatas=metadatas,
        ids=ids
    )

    print(f"âœ… {len(chunks)} vecteurs stockÃ©s dans la collection '{collection_name}'")
    return collection


def list_collections() -> list[str]:
    """Retourne la liste des collections disponibles dans ChromaDB."""
    client = get_chroma_client()
    collections = client.list_collections()
    return [col.name for col in collections]


# Test rapide si on lance ce fichier directement
if __name__ == "__main__":
    test_chunks = [
        "DÃ©veloppeur Python avec 5 ans d'expÃ©rience en machine learning.",
        "CompÃ©tences : LangChain, Docker, AWS, FastAPI.",
        "ExpÃ©rience en dÃ©ploiement de modÃ¨les en production.",
    ]

    collection = embed_and_store(
        chunks=test_chunks,
        collection_name="test_collection",
        metadata={"type": "cv", "filename": "test"}
    )

    print(f"\nðŸ“‹ Collections disponibles : {list_collections()}")
    print(f"ðŸ“Š Nombre de vecteurs : {collection.count()}")